================================================================================
== TODO ========================================================================
================================================================================
* choose what I'd like to do
* ideas papers said "further study needed" for:
  - intriguing props of NN: For MNIST, we do not have results for convolutional models yet, but […] may behave similarly as well.
  - towards deep NN arch robust to adversial examples: Evaluate the performance loss due to layer-wise penalties […]. In addition, exploring non-Euclidean adversarial examples […] could lead to insights into semantic attributes of features learned at high levels of representation.

* then on subset of ImageNet (link in blog, ILSVRC)
* compare CNN code for similar objects (animals breeds, similar to article), eg: v(bulldog) - v(dalmatian) ~ v(cat siamoi) - v(cat egyptian)
* compare line-wise in CNN code space, find directions/segments that make sense, perpendicular, other directions?
  CNN code is taken from the layer before the last (before softmax) in article
* can use t-SNE again (or show as image for conv layers)
* try on other lower layers

* later on: try to combine two/or more transformations at the same time, see if it's a grid (row=1st transf, cols=2nd transfo) in t-SNE space, separate plots, by pairs

* later on: given a simple shape which a few neurons detect in a model A, how can we relate to neurons in a second model B trained with translation-invariance (wrt to neuron activation: activated at the same time in A and B but with transalation in B). Can we find a relation between neurons. (ref to visualizing cnns, forget for now because it's hard)

* compute measure of closeness ("energy") in ip1 layer (instead of t-sne heavy) to compare different models, how they can "cluster" or separate samples (compared to label, shape, etc), want to compare different data-augmentation datasets by transformation (shift close for shift-augmentation, rotated close for rotation-augmentation)

* analysis of adversial attack (better graphs, data-augmented adversial training)
* compare distance between original image and adversial in image space versus vector space (in which layer it happens), write code to detect the responsible weights for divergence (for adversial) or convergence (for invariance), comparing two models

* boundary detection (dataset BSDS): train boundary detector (there is a curve passing through center pixel = 1, or 0) on patches of an image. plot t-sne (of all patches of a single image), interpret what clusters means, (never done before?), what about cluster intersections?
* boundary detection different models: 0/1 curve on central pixel, multi-class based on angles (8 classes), angle regression (directly: loss - angle) <- never done in CNN (?)

* shift-invariance: with an other (easy) dataset, boundary detection
* try to relate data augmentation (cost of freedom-degrees invariance) wrt accuracy, and can we measure the capacity (afterward)?
* try to plot capacity during training, compare different data augmentation (original versus shift), maybe gradient contribution is higher for a certain sort of degrees

* add more motivations/justification to research (goal-oriented)
* data-augmentation: how can we justify our artifially-transformed testset? no, we can't. Instead: test over meaniful/natural dataset like house number (google street) dataset.
* train model to cluster similar samples together in vector space (transformation-invariance)


================================================================================
== DONE ========================================================================
================================================================================

* find papers of "intriguing papers" that retrain on adversial
* read papers
* read papers from email
* see video for intuition Are Deep Networks a Solution to Curse of Dimensionality
* read blog colah (article Visualizing Representations)
* compare output difference (invariance) in t-SNE space wrt to:
    - translation
    - rotation (take bigger image, crop with enough margin)
    - deformation (translate with local direction for displacement)
    - illumination/brightness
    - colors (raw vs "enhanced")
* reproduce colah visualisation on MNIST (because small dataset), t-SNE map (see how projections are clustered)

* plot (in video) the position of continously deformed input in CNN code t-SNE transformation (try to see pattern) <-- interactive plot
* explore other articles on colah, eg: NLP cluster map, table
* merge t-SNE, all transformations of all my numbers together, then hide on plots the one I'm not interested
* take a look at samples close to our transformed points (esp extreme of rotation), try to plot images instead of points (only for them?), try to make it clear <-- interactive plot
* use a point from the testset instead of a handmade one (mine is outliners, is that normal? part of t-SNE or because I made them, still on boundary)
* make video of plots with visualisation of closest points (1 frame = 1 transfo, in this order of increasing) <-- interactive plot
* interactive plot in Js, try quickly
* try to train dataset but adding translations (test if it learns of translation invariance)
* with shift-invariance: retrain correctly with test images and correct range x-y
* with shift-invariance: for each digit localize distorted digits, see if they form a cluster inside the digit cluster, can we understand the shape, is there one at all?
* try for all classes to apply distortions to one test image that is close to the cluster of pos/neg rotated input (see what happens, join/straight line/apart)
* add key for plot (to zoom-in/out)
* rerun different seed closest t-sne
* get the closest point to the original digit (apply t-sne)
* shift invariance: test transfo only with a single sample x+y (no grid) to be fair
* shift invariance: be fair with train range versus test range
* add adversial transformation into the framework
