* choose what I'd like to do
* find papers of "intriguing papers" that retrain on adversial
* visualize output against input distortions (interactive programs?)


* read papers
* read papers from email
* see video for intuition Are Deep Networks a Solution to Curse of Dimensionality
* read blog colah (article Visualizing Representations)

* reproduce colah visualisation on MNIST (because small dataset), t-SNE map (see how projections are clustered)
* then on subset of ImageNet (link in blog, ILSVRC)
* compare output difference (invariance) in t-SNE space wrt to:
    - translation
    - rotation (take bigger image, crop with enough margin)
    - deformation (translate with local direction for displacement)
    - illumination/brightness
    - colors (raw vs "enhanced")
* compare CNN code for similar objects (animals breeds, similar to article), eg: v(bulldog) - v(dalmatian) ~ v(cat siamoi) - v(cat egyptian)
* compare line-wise in CNN code space, find directions/segments that make sense, perpendicular, other directions?
  CNN code is taken from the layer before the last (before softmax) in article
* can use t-SNE again (or show as image for conv layers)
* try on other lower layers
* explore other articles on colah, eg: NLP cluster map, table

* plot (in video) the position of continously deformed input in CNN code
  t-SNE transformation (try to see pattern)

papers said "further study needed" for:
* intriguing props of NN: For MNIST, we do not have results for convolutional models yet, but […] may behave similarly as well.
* towards deep NN arch robust to adversial examples: Evaluate the performance loss due to layer-wise penalties […]. In addition, exploring non-Euclidean adversarial examples […] could lead to insights into semantic attributes of features learned at high levels of representation.
