* choose what I'd like to do
* find papers of "intriguing papers" that retrain on adversial
* read papers
* read papers from email
* see video for intuition Are Deep Networks a Solution to Curse of Dimensionality
* read blog colah (article Visualizing Representations)

* reproduce colah visualisation on MNIST (because small dataset), t-SNE map (see how projections are clustered)
* then on subset of ImageNet (link in blog, ILSVRC)
* compare output difference (invariance) in t-SNE space wrt to:
    - translation
    - rotation (take bigger image, crop with enough margin)
    - deformation (translate with local direction for displacement)
    - illumination/brightness
    - colors (raw vs "enhanced")
* compare CNN code for similar objects (animals breeds, similar to article), eg: v(bulldog) - v(dalmatian) ~ v(cat siamoi) - v(cat egyptian)
* compare line-wise in CNN code space, find directions/segments that make sense, perpendicular, other directions?
  CNN code is taken from the layer before the last (before softmax) in article
* can use t-SNE again (or show as image for conv layers)
* try on other lower layers
* explore other articles on colah, eg: NLP cluster map, table

* plot (in video) the position of continously deformed input in CNN code
  t-SNE transformation (try to see pattern)

papers said "further study needed" for:
* intriguing props of NN: For MNIST, we do not have results for convolutional models yet, but […] may behave similarly as well.
* towards deep NN arch robust to adversial examples: Evaluate the performance loss due to layer-wise penalties […]. In addition, exploring non-Euclidean adversarial examples […] could lead to insights into semantic attributes of features learned at high levels of representation.

* merge t-SNE, all transformations of all my numbers together, then hide on plots the one I'm not interested
* try to train dataset but adding translations (test if it learns of translation anviarance)
* try for all classes to apply distortions to one test image that is close to the the cluster of pos/neg rotated input (see what happpens, join/straight line/apart)
* take a look at samples close to our transformed points (esp extreme of rotation), try to plot images instead of points (only for them?), try to make it clear
* use a point from the testset instead of a handmade one (mine is outliners, is that normal? part of t-SNE or because I made them, still on boundary)
* make video of plots with visualisation of closest points (1 frame = 1 transfo, in this order of increasing)
* later on: try to combine two/or more transformations at the same time, see if it's a grid (row=1st transf, cols=2nd transfo) in t-SNE space, separate plots, by pairs

* interactive plot in Js, try quickly
* add adversial transformation into the framework
* with shift-invariance: retrain correctly with test images and correct range x-y
* with shift-invariance: for each digit localize distorted digits, see if they form a cluster inside the digit cluster, can we understand the shape, is there one at all?
* later on: given a simple shape which a few neurons detect in a model A, how can we relate to neurons in a second model B trained with translation-invariance (wrt to neuron activation: activated at the same time in A and B but with transalation in B). Can we find a relation between neurons. (ref to visualizing cnns, forget for now because it's hard)
