\documentclass[a4paper,12pt]{article}

\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{a4wide}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{lastpage}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}

\lhead{Axel Angel}
\rhead{Properties of Convolutional Neural Networks}
\chead{Report}
\rfoot{Page \thepage\ of \pageref{LastPage}}
\lfoot{\today}

\pdfinfo{
    /Author (Authors)
    /Title (Title)
    /Subject (Subject)
    }

\begin{document}
Write about results, raw sketch to complete.

why chose caffe? because easy, various models available, optimized and flexible.

papers use pca before t-sne, sklearn recommends too, in practice it works well.

some papers found that cnn models are easily fooled by adversial noise, because too linear? because image space too wide?

some papers can train using adversial examples. mnist dataset is not resistant to many generations of adversial training. imagenet works better (because natural images?)

we need a way to formalize invariance, resitance to adversial noise, deformations. present results and compare models, attacks and present numbers.

lenet on mnist can be easily fooled by translations, because dataset is heavily normalized, translation-invariance is weak. small rotations works well but can fool easily. seems invariant to contrast (invariant filters?).

interactive tool findings? discontinuities in the output, we can fool it with certain angles. we see the receptive field by shifting, after some margin it goes non-sense

transfo tracer findings? how to plot better? we find pattern in the t-SNE. Lines for positive angles, a curve for negative angles, does it mean anything since its t-SNE? invariant transformations? blur has small impact, why? shift is important after a certain threshold (margin? recetivity field size?), why? can we relate this to the CNN-code: easy, hard?

train translation-invariance: tried to train lenet with multiple copies of each but shifted of the same amount (fixed ranges), but the accuracy on original test is very low (30\%) probably because it learned positional-dependent features instead of real translation invariance! The shifted test set has 92\% accuracy though.

train translation-invariance: with random translation (among given range), one per axis at most (original + shift x + shift y).

after ensuring my translated training set is correct (high accuracy and so), the t-sne seems ``overcrowded'' or much less separated than before. It's like for eevery digit half is clustered and the rest is spread. Probably one region for centered digit, one spread region for displaced. There are a lot of overlap but there seems to have cluster with the similar translation offset (but different digit!). Lots of clusters grouping similar translation offsets: left-shifted, right-shifted, upper-shifted, lower-shifted. I suspect the network learned there are two/three kind of samples not-shifted and shifted ones (left-right up-down kinds). I should try to have a sample appearing once with x-y-combined translation at random.

with translation-invariance: models keep quite good accuracy on original testset, but lost 2\% compared to original model. Accuracy on shifted testset is much lower (down to 91\%) probably because lots of sample are out of the receptive fields or too much information was lost to disambiguate.
\end{document}
